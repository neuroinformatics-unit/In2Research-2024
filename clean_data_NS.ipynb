{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data using `movement`\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from movement.io import load_poses, save_poses\n",
    "from movement.utils.reports import report_nan_values\n",
    "\n",
    "# Use function from utils.py, located within the same directory\n",
    "from utils import reshape_loaded_ds, clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and create paths\n",
    "First let's find the data folder on the current machine and check its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be loaded from /Users/nsirmpilatze/Data/in2research2024\n",
      "Subfolder SB019 has been found\n",
      "Subfolder SB021 has been found\n"
     ]
    }
   ],
   "source": [
    "# Exchange the path to the data folder with the correct one on your system\n",
    "data_folder = Path(\"/Users/nsirmpilatze/Data/in2research2024\")\n",
    "assert data_folder.exists()  # Will raise an error if the path does not exist\n",
    "print(f\"Data will be loaded from {data_folder}\")\n",
    "\n",
    "# The following resident mouse IDs must be present as subfolders in the data folder\n",
    "resident_ids = [\"SB019\", \"SB021\"]\n",
    "for id in resident_ids:\n",
    "    assert (data_folder / id).exists()\n",
    "    print(f\"Subfolder {id} has been found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create subfolders for saving cleaned data, plots and reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data will be saved in /Users/nsirmpilatze/Data/in2research2024/clean_data\n",
      "Plots will be saved in /Users/nsirmpilatze/Data/in2research2024/plots\n",
      "Reports will be saved in /Users/nsirmpilatze/Data/in2research2024/reports\n"
     ]
    }
   ],
   "source": [
    "clean_data_folder = data_folder / \"clean_data\"\n",
    "clean_data_folder.mkdir(exist_ok=True)\n",
    "print(f\"Cleaned data will be saved in {clean_data_folder}\")\n",
    "\n",
    "plot_folder = data_folder / \"plots\"\n",
    "plot_folder.mkdir(exist_ok=True)\n",
    "print(f\"Plots will be saved in {plot_folder}\")\n",
    "\n",
    "report_folder = data_folder / \"reports\"\n",
    "report_folder.mkdir(exist_ok=True)\n",
    "print(f\"Reports will be saved in {report_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the video file names for each mouse pair, and the corresponding time intervals during which both mice were present in the arena. The times are given in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"SB019_female4\": dict(\n",
    "        file_name=\"220719_SB019_FM001_female4_2022-07-19-181533DLC_resnet50_shanice_allNov29shuffle1_196000_filtered.csv\",\n",
    "        time_on=30,\n",
    "        time_off=330,\n",
    "    ),\n",
    "    \"SB019_male2\": dict(\n",
    "        file_name=\"220719_SB019_FM001_male2_2022-07-19-172457DLC_resnet50_shanice_allNov29shuffle1_196000_filtered.csv\",\n",
    "        time_on=29,\n",
    "        time_off=323,\n",
    "    ),\n",
    "    \"SB021_female2\": dict(\n",
    "        file_name=\"220804_SB021_FM001_female2_2022-08-04-223620DLC_resnet50_shanice_allNov29shuffle1_196000_filtered.csv\",\n",
    "        time_on=40,\n",
    "        time_off=350,\n",
    "    ),\n",
    "    \"SB021_male1\": dict(\n",
    "        file_name=\"220804_SB021_FM001_male1_2022-08-04-215616DLC_resnet50_shanice_allNov29shuffle1_196000_filtered.csv\",\n",
    "        time_on=31,\n",
    "        time_off=334,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the names of the tracked individuals and keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals = [\"resident\", \"intruder\"]\n",
    "keypoint_names = [\n",
    "    \"nose\",\n",
    "    \"leftear\",\n",
    "    \"rightear\", \n",
    "    \"butt\",\n",
    "    \"neck\",\n",
    "    \"lefthip\",\n",
    "    \"righthip\",\n",
    "    \"leftshoulder\", \n",
    "    \"rightshoulder\",\n",
    "    \"lowerback\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data using a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for SB019 and female4\n",
      "Data has been loaded successfully.\n",
      "Data has been reshaped successfully into a dataset with two individuals: ['resident', 'intruder']\n",
      "Selected interval from 30 to 330 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data and saved cleaned dataset.\n",
      "Diagnostic plots have been generated and saved to disk.\n",
      "Finished processing data for SB019 and female4.\n",
      "\n",
      "Processing data for SB019 and male2\n",
      "Data has been loaded successfully.\n",
      "Data has been reshaped successfully into a dataset with two individuals: ['resident', 'intruder']\n",
      "Selected interval from 29 to 323 seconds.\n",
      "Filtered data and saved cleaned dataset.\n",
      "Diagnostic plots have been generated and saved to disk.\n",
      "Finished processing data for SB019 and male2.\n",
      "\n",
      "Processing data for SB021 and female2\n",
      "Data has been loaded successfully.\n",
      "Data has been reshaped successfully into a dataset with two individuals: ['resident', 'intruder']\n",
      "Selected interval from 40 to 350 seconds.\n",
      "Filtered data and saved cleaned dataset.\n",
      "Diagnostic plots have been generated and saved to disk.\n",
      "Finished processing data for SB021 and female2.\n",
      "\n",
      "Processing data for SB021 and male1\n",
      "Data has been loaded successfully.\n",
      "Data has been reshaped successfully into a dataset with two individuals: ['resident', 'intruder']\n",
      "Selected interval from 31 to 334 seconds.\n",
      "Filtered data and saved cleaned dataset.\n",
      "Diagnostic plots have been generated and saved to disk.\n",
      "Finished processing data for SB021 and male1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pair_name, pair_dict in data.items():\n",
    "    # Check if the file exists\n",
    "    resident_id, intruder_id = pair_name.split(\"_\")\n",
    "    file_path = data_folder / resident_id / pair_dict[\"file_name\"]\n",
    "    assert file_path.is_file()\n",
    "    print(f\"Processing data for {resident_id} and {intruder_id}\")\n",
    "\n",
    "    # Load the data\n",
    "    ds_raw = load_poses.from_dlc_file(file_path, fps=50)\n",
    "    print(\"Data has been loaded successfully.\")\n",
    "\n",
    "    # Reshape the data into a multi-individual dataset\n",
    "    ds = reshape_loaded_ds(ds_raw, individuals, keypoint_names)\n",
    "    print(f\"Data has been reshaped successfully into a dataset with two individuals: {individuals}\")\n",
    "\n",
    "    # Select the interval of interest\n",
    "    ds  = ds.sel(time=slice(pair_dict[\"time_on\"], pair_dict[\"time_off\"]))\n",
    "    print(f\"Selected interval from {pair_dict['time_on']} to {pair_dict['time_off']} seconds.\")\n",
    "\n",
    "    # Clean the data with a combination of confidence thresholding, interpolation, and smoothing\n",
    "    ds_clean = clean_data(\n",
    "        ds,\n",
    "        confidence_threshold=0.8,\n",
    "        interp_max_gap=25,\n",
    "        smooth_window_size=7,\n",
    "        smooth_min_periods=2,\n",
    "    )\n",
    "    # Save the cleaned data to a new CSV file\n",
    "    clean_file_path = clean_data_folder / f\"{pair_name}_clean.csv\"\n",
    "    if clean_file_path.exists():\n",
    "        os.remove(clean_file_path)\n",
    "    save_poses.to_dlc_file(\n",
    "        ds_clean, clean_file_path, split_individuals=False,\n",
    "    )\n",
    "    # Generate a report on the number of NaN values in the cleaned dataset\n",
    "    # and save it to a text file\n",
    "    nan_report = report_nan_values(ds_clean[\"position\"], f\"clean data for {pair_name}\")\n",
    "    with open(report_folder /  f\"{pair_name}_clean_nan_report.txt\", \"w\") as f:\n",
    "        f.write(nan_report)\n",
    "    print(\"Filtered data and saved cleaned dataset.\")\n",
    "\n",
    "    # Generate time series plots for all keypoints\n",
    "    for kpt_to_plot  in ds.keypoints.values:\n",
    "        # plot raw position over time for a given keypoint\n",
    "        ds[\"position\"].sel(keypoints=kpt_to_plot).plot.line(\n",
    "            x=\"time\", hue=\"individuals\", row=\"space\", aspect=5, size=2.5\n",
    "        )\n",
    "        plt.savefig(plot_folder / f\"{resident_id}_{intruder_id}_{kpt_to_plot}_position_raw_plot.png\")\n",
    "        plt.close()\n",
    "        # plot cleaned position over time for a given keypoint\n",
    "        ds_clean[\"position\"].sel(keypoints=kpt_to_plot).plot.line(\n",
    "            x=\"time\", hue=\"individuals\", row=\"space\", aspect=5, size=2.5\n",
    "        )\n",
    "        plt.savefig(plot_folder / f\"{resident_id}_{intruder_id}_{kpt_to_plot}_position_clean_plot.png\")\n",
    "        plt.close()\n",
    "        # plot confidence over time for a given keypoint\n",
    "        ds_clean[\"confidence\"].sel(keypoints=kpt_to_plot).plot.line(\n",
    "            x=\"time\", hue=\"individuals\", aspect=5, size=2.5\n",
    "        )\n",
    "        plt.savefig(plot_folder / f\"{resident_id}_{intruder_id}_{kpt_to_plot}_confidence_plot.png\")\n",
    "        plt.close()\n",
    "    print(\"Diagnostic plots have been generated and saved to disk.\")\n",
    "\n",
    "\n",
    "    print(f\"Finished processing data for {resident_id} and {intruder_id}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "In2Research2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
